{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_size = \"large-v3\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'en' with probability 0.973996\n",
      "[0.56s -> 6.60s]  hello good morning I am testing the whisper module to ensure if you are able\n",
      "[6.60s -> 11.36s]  to do speech to text translation on device\n"
     ]
    }
   ],
   "source": [
    "segments, info = model.transcribe(\"audio.m4a\", beam_size=5)\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language 'ta' with probability 0.967740\n",
      "[0.00s -> 4.16s]  வானம் பழிகிறது பூமி விளகிறது உனக்கு எதற்கு தரவேண்டும் மட்டி\n"
     ]
    }
   ],
   "source": [
    "segments, info = model.transcribe(\"tamil.m4a\", beam_size=5)\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text:\n",
      "\n",
      "Summary:\n",
      "in shops, things are kept in separate packets, and each one specialises in some particular article or sets of articles. but in an exhibition, hundreds of shops join to make all varieties of things available. this'speech' today is a new experience for you, but for Me it is not new. when the Formless becomes One with form, it has to fulfil the Mission in various ways.\n"
     ]
    }
   ],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration\n",
    "\n",
    "# Load pre-trained T5 model and tokenizer\n",
    "model_name = \"t5-large\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "\n",
    "# Input text to be summarized\n",
    "input_text = \"\"\"\n",
    "In shops, things are kept in separate packets, and each one specialises in\n",
    "some particular article or sets of articles. But in an exhibition, hundreds of\n",
    "shops join to make all varieties of things available, and there is a great deal of\n",
    "window-dressing, arrangement, and display. I have been all these days\n",
    "generally giving individual advice, like the packets available in shops, and\n",
    "giving answers to individual questions. This 'speech' today is a new\n",
    "experience for you. I am addressing a gathering today, but even though it\n",
    "may be new to you, for Me it is not new. I have given advice to large\n",
    "gatherings before, though not in this Appearance. Whenever the Formless\n",
    "becomes One with Form, It has to fulfil the Mission, and It does so in various\n",
    "ways. But the one purpose, the re-education of Man, persists, whatever the\n",
    "era. The first sixteen years of this Life have been, as I have often told you, the\n",
    "period when divine child sport predominated, and the next sixteen is being\n",
    "spent mostly in miracles in order to give joy to this generation. Joy and\n",
    "contentment are short-lived sensations; you have to catch that mood and\n",
    "make it a permanent possession: bliss ( ananda ). After the thirty-second year,\n",
    "you will see Me active more and more in the task of spiritual instruction -\n",
    "teaching erring humanity and in directing the world along the path of truth,\n",
    "righteousness, peace, and love ( sathya , dharma , santhi , and prema ). Not that\n",
    "I am determined to exclude plays and miracles from My activity after that. I\n",
    "only mean that reestablishing dharma, correcting the crookedness of the\n",
    "human mind, and guiding humanity back to Sanathana Dharma (Eternal\n",
    "Universal Religion) will be My task thereafter. Do not be led away by doubt\n",
    "and vain argument; do not question how and whether I can do all this. The\n",
    "cowherds of Brindavan also doubted whether the little boy (Krishna) who\n",
    "grew in their midst could lift Govardana mountain and hold it aloft! The thing\n",
    "needed is faith, and yet more faith.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize and summarize the input text using T5\n",
    "inputs = tokenizer.encode(\"summarize: \" + input_text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "summary_ids = model.generate(inputs, max_length=150, min_length=20, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Decode and output the summary\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(\"Original Text:\")\n",
    "# print(input_text)\n",
    "print(\"\\nSummary:\")\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
